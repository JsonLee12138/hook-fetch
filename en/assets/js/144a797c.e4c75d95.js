"use strict";(self.webpackChunkhook_fetch_docs=self.webpackChunkhook_fetch_docs||[]).push([[2055],{8258:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>i,contentTitle:()=>c,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"streaming","title":"Streaming","description":"Hook-Fetch provides powerful streaming data processing capabilities, particularly suitable for handling Server-Sent Events (SSE), real-time data streams, and large file transfers.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/streaming.md","sourceDirName":".","slug":"/streaming","permalink":"/hook-fetch/en/docs/streaming","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"Json_Lee","lastUpdatedAt":1751963620000,"sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Plugin System","permalink":"/hook-fetch/en/docs/plugins"},"next":{"title":"Framework Integration","permalink":"/hook-fetch/en/docs/framework-integration"}}');var s=r(4848),a=r(8453);const o={sidebar_position:5},c="Streaming",i={},l=[{value:"Basic Streaming",id:"basic-streaming",level:2},{value:"Using the stream() Method",id:"using-the-stream-method",level:3},{value:"StreamContext Structure",id:"streamcontext-structure",level:3},{value:"Server-Sent Events (SSE)",id:"server-sent-events-sse",level:2},{value:"Basic SSE Processing",id:"basic-sse-processing",level:3},{value:"Using SSE Plugin",id:"using-sse-plugin",level:3},{value:"Real-time Chat Example",id:"real-time-chat-example",level:2},{value:"ChatGPT-style Streaming Chat",id:"chatgpt-style-streaming-chat",level:3},{value:"Large File Download with Progress",id:"large-file-download-with-progress",level:2},{value:"Download with Progress Tracking",id:"download-with-progress-tracking",level:3},{value:"Advanced Streaming Patterns",id:"advanced-streaming-patterns",level:2},{value:"Custom Stream Processing",id:"custom-stream-processing",level:3},{value:"Stream Error Handling",id:"stream-error-handling",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Memory Management",id:"1-memory-management",level:3},{value:"2. Stream Cancellation",id:"2-stream-cancellation",level:3},{value:"3. Backpressure Handling",id:"3-backpressure-handling",level:3}];function u(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"streaming",children:"Streaming"})}),"\n",(0,s.jsx)(n.p,{children:"Hook-Fetch provides powerful streaming data processing capabilities, particularly suitable for handling Server-Sent Events (SSE), real-time data streams, and large file transfers."}),"\n",(0,s.jsx)(n.h2,{id:"basic-streaming",children:"Basic Streaming"}),"\n",(0,s.jsx)(n.h3,{id:"using-the-stream-method",children:"Using the stream() Method"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import hookFetch from 'hook-fetch';\n\nconst request = hookFetch('https://api.example.com/stream');\n\nfor await (const chunk of request.stream()) {\n  console.log('Received chunk:', chunk.result);\n  console.log('Raw bytes:', chunk.source);\n  console.log('Error:', chunk.error);\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"streamcontext-structure",children:"StreamContext Structure"}),"\n",(0,s.jsx)(n.p,{children:"Each streaming data chunk contains the following information:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface StreamContext<T = unknown> {\n  result: T;                  // Processed data\n  source: Uint8Array;         // Raw byte data\n  error: unknown | null;      // Error information (if any)\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"server-sent-events-sse",children:"Server-Sent Events (SSE)"}),"\n",(0,s.jsx)(n.h3,{id:"basic-sse-processing",children:"Basic SSE Processing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// Simple SSE processing\nconst sseRequest = hookFetch('https://api.example.com/sse');\n\nfor await (const chunk of sseRequest.stream()) {\n  const text = new TextDecoder().decode(chunk.source);\n  console.log('SSE data:', text);\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"using-sse-plugin",children:"Using SSE Plugin"}),"\n",(0,s.jsx)(n.p,{children:"Hook-Fetch provides a dedicated SSE plugin to simplify processing:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { sseTextDecoderPlugin } from 'hook-fetch/plugins/sse';\n\nconst api = hookFetch.create({\n  plugins: [\n    sseTextDecoderPlugin({\n      json: true,                 // Auto-parse JSON\n      prefix: 'data: ',          // Remove \"data: \" prefix\n      splitSeparator: '\\n\\n',    // Event separator\n      lineSeparator: '\\n',       // Line separator\n      trim: true,                // Trim whitespace\n      doneSymbol: '[DONE]'       // End marker\n    })\n  ]\n});\n\n// Use configured SSE request\nfor await (const chunk of api.get('/sse-endpoint').stream()) {\n  console.log('Parsed SSE data:', chunk.result);\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"real-time-chat-example",children:"Real-time Chat Example"}),"\n",(0,s.jsx)(n.h3,{id:"chatgpt-style-streaming-chat",children:"ChatGPT-style Streaming Chat"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { sseTextDecoderPlugin } from 'hook-fetch/plugins/sse';\n\nconst chatApi = hookFetch.create({\n  baseURL: 'https://api.openai.com/v1',\n  headers: {\n    'Authorization': 'Bearer your-api-key',\n    'Content-Type': 'application/json'\n  },\n  plugins: [\n    sseTextDecoderPlugin({\n      json: true,\n      prefix: 'data: ',\n      doneSymbol: '[DONE]'\n    })\n  ]\n});\n\nasync function streamChat(message: string) {\n  const request = chatApi.post('/chat/completions', {\n    model: 'gpt-3.5-turbo',\n    messages: [{ role: 'user', content: message }],\n    stream: true\n  });\n\n  let fullResponse = '';\n\n  for await (const chunk of request.stream()) {\n    const delta = chunk.result?.choices?.[0]?.delta?.content;\n    if (delta) {\n      fullResponse += delta;\n      console.log('Streaming:', delta);\n      // Update UI display\n      updateChatUI(fullResponse);\n    }\n  }\n\n  return fullResponse;\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"large-file-download-with-progress",children:"Large File Download with Progress"}),"\n",(0,s.jsx)(n.h3,{id:"download-with-progress-tracking",children:"Download with Progress Tracking"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"async function downloadWithProgress(url: string, filename: string) {\n  const request = hookFetch(url);\n  const response = await request;\n\n  if (!response.ok) {\n    throw new Error(`Download failed: ${response.status}`);\n  }\n\n  const contentLength = response.headers.get('content-length');\n  const total = contentLength ? parseInt(contentLength, 10) : 0;\n  let loaded = 0;\n\n  const chunks: Uint8Array[] = [];\n\n  for await (const chunk of request.stream()) {\n    if (chunk.error) {\n      throw chunk.error;\n    }\n\n    chunks.push(chunk.source);\n    loaded += chunk.source.length;\n\n    // Update progress\n    const progress = total > 0 ? (loaded / total) * 100 : 0;\n    console.log(`Download progress: ${progress.toFixed(2)}%`);\n    updateProgressBar(progress);\n  }\n\n  // Merge all chunks\n  const blob = new Blob(chunks);\n\n  // Create download link\n  const downloadUrl = URL.createObjectURL(blob);\n  const a = document.createElement('a');\n  a.href = downloadUrl;\n  a.download = filename;\n  a.click();\n\n  // Cleanup\n  URL.revokeObjectURL(downloadUrl);\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"advanced-streaming-patterns",children:"Advanced Streaming Patterns"}),"\n",(0,s.jsx)(n.h3,{id:"custom-stream-processing",children:"Custom Stream Processing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const customStreamPlugin = () => ({\n  name: 'custom-stream',\n  async transformStreamChunk(chunk, config) {\n    if (!chunk.error && chunk.result) {\n      // Custom processing logic\n      const processedData = processChunk(chunk.result);\n      chunk.result = processedData;\n    }\n    return chunk;\n  }\n});\n\nconst api = hookFetch.create({\n  plugins: [customStreamPlugin()]\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"stream-error-handling",children:"Stream Error Handling"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"async function robustStreaming(url: string) {\n  const request = hookFetch(url);\n\n  try {\n    for await (const chunk of request.stream()) {\n      if (chunk.error) {\n        console.error('Stream error:', chunk.error);\n        // Handle stream-specific errors\n        continue;\n      }\n\n      // Process successful chunk\n      processChunk(chunk.result);\n    }\n  } catch (error) {\n    console.error('Streaming failed:', error);\n    // Handle overall streaming failure\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsx)(n.h3,{id:"1-memory-management",children:"1. Memory Management"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// Use generators for large streams\nasync function* processLargeStream(url: string) {\n  const request = hookFetch(url);\n\n  for await (const chunk of request.stream()) {\n    if (!chunk.error) {\n      yield processChunk(chunk.result);\n    }\n  }\n}\n\n// Use the generator\nfor await (const processedChunk of processLargeStream('/large-stream')) {\n  console.log(processedChunk);\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"2-stream-cancellation",children:"2. Stream Cancellation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const controller = new AbortController();\n\nconst request = hookFetch('/stream', {\n  signal: controller.signal\n});\n\n// Cancel after 30 seconds\nsetTimeout(() => {\n  controller.abort();\n}, 30000);\n\ntry {\n  for await (const chunk of request.stream()) {\n    console.log(chunk.result);\n  }\n} catch (error) {\n  if (error.name === 'AbortError') {\n    console.log('Stream cancelled');\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"3-backpressure-handling",children:"3. Backpressure Handling"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"async function handleBackpressure(url: string) {\n  const request = hookFetch(url);\n  const buffer: any[] = [];\n  const maxBufferSize = 100;\n\n  for await (const chunk of request.stream()) {\n    if (!chunk.error) {\n      buffer.push(chunk.result);\n\n      // Process buffer when it's full\n      if (buffer.length >= maxBufferSize) {\n        await processBatch(buffer.splice(0, maxBufferSize));\n      }\n    }\n  }\n\n  // Process remaining items\n  if (buffer.length > 0) {\n    await processBatch(buffer);\n  }\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"Streaming is one of Hook-Fetch's most powerful features, enabling real-time data processing and efficient handling of large datasets. The plugin system makes it easy to customize streaming behavior for specific use cases."})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>c});var t=r(6540);const s={},a=t.createContext(s);function o(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);